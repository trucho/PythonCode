ggtitle(tempName) +
theme_classic(base_size = 16, base_rect_size = 5) +
theme(axis.line = element_line(size = 2), axis.text = element_text(size=14))
# p2 = ggplot() + geom_line(aes(x = fitWeights, y = tempData[[tempName]][,2]), color=rgb(1, 0, 0, .5)) +
#    geom_line(aes(x = c(tempBP,tempBP), y = c(0,max(tempData[[tempName]][,2]))), color=rgb(0, .5, .8, .8)) +
#    ylab("Fluo (a.u.)") +
#    xlim(p_lo, p_hi) +
#    theme_classic()
#
# ggarrange(p, p2, heights = c(2, 0.7),ncol = 1, nrow = 2, align = "v")
ggplotly(p)
# or plot whole ladder by itself
# plot(fitWeights, tempData[[tempName]][,2], typ='l', xlim=c(0, 100))
# export data as csv into same folder and with same name
write.csv(data.frame("size"=fitWeights,"fluo"=tempData[[tempName]][,1],"ladder"=tempData[[tempName]][,2]),paste(paste(dir.fsa,gsub('.{0,4}$', '', tempName),sep = "/"),".csv", sep=""),row.names = FALSE) +
message(paste("Saved analysis for:",tempName)) +
print(tempBP) + print(tempBP2) + print(tempBP2 - tempBP)
# dev.off()
# ------------------------------------------------------------------------------------------------------------------------------------------------
# get single file (run section with command+alt+T)
i=i+1
if (i>length(fsaNames)) {stop('Finished analyzing files')}
tempName = fsaNames[i]; message(paste("Analyzing:",fsaNames[i]))
tempData <- fsaData[tempName]
class(tempData) <- "fsa_stored"
# check if this has been done
if (file.exists(paste(paste(dir.fsa,gsub('.{0,4}$', '', tempName),sep = "/"),".csv", sep=""))) {message("Already calibrated and exported; no need to redo")}
# for fragment analysis using FAM13 and LIZ500, relevant channels are 1 and 5 respectively
chDNA = 1; chLadder = 10;
# plot data to assess if it's worth it remapping
# plot(tempData[[tempName]][,1], typ='l',xlim=c(1700,length(tempData[[tempName]][,1])),ylim=c(0,30000))
dlo=200;
dhi=6100;
plot(tempData[[tempName]][,chDNA], typ='l',xlim=c(dlo,dhi),ylim=c(min(tempData[[tempName]][dlo:dhi,chDNA]),max(tempData[[tempName]][dlo:dhi,chDNA])), main = tempName)
# figure out threshold by checking liz500 channel
plot(tempData[[tempName]][,chLadder], xlim=c(100,2200), typ='l')
ilim01 = 1200;
plot(tempData[[tempName]][,chLadder], xlim =c(ilim01,6000), typ='l')
ilim02 = 6200;
plot(tempData[[tempName]][ilim01:ilim02,chLadder], typ='l') # 16 peaks for liz500 (15 peaks if removed '35' marker)
tempData[[tempName]] = tempData[[tempName]][ilim01:ilim02,c(chDNA,chLadder)]
# plot(tempData[[tempName]][,2], typ='l') # 16 peaks for liz500 (15 peaks if removed '35' marker)
# guessThreshold = quantile(tempData[[tempName]][,2],.992);
guessThreshold = quantile(tempData[[tempName]][,2],.98);
guessThreshold = 50 ;
# match ladder (works better if higher values when noise is high)
ladderData = ladder.info.attach(stored=tempData, ladder=liz500, method='iter2', draw=TRUE, ladd.init.thresh=guessThreshold)
# replot ladder if needed to play with threshold
# plot(tempData[[tempName]][,2], typ='l') # 16 peaks for liz500
# run manual correction if needed
# ladderData = ladder.corrector(stored=tempData, to.correct = tempName, ladder=liz500)
if (file.exists(paste(paste(dir.fsa,gsub('.{0,4}$', '', tempName),sep = "/"),".csv", sep=""))) {message("Already calibrated and exported; no need to redo")}
# ------------------------------------------------------------------------------------------------------------------------------------------------
# ladder is stored as an environment (hidden) variable -> list.data.covarrubias[[tempName]]
ladder = data.frame("p" = list.data.covarrubias[[tempName]]$pos, "w"=list.data.covarrubias[[tempName]]$wei)
# if all fails, do completely manual mapping
# plot(tempData[[tempName]][,2], typ='l', xlim = c(500,1000))
# ladder = data.frame("p" = c(118,270,410,628,685,738,958,1215,1508,1718,1776,2058,2318,2532,2578), "w"=liz500)
# ladder
# fit ladder with a 5th degree polynomial (this is what fragman uses)
polyModel = lm(w ~ poly(p,5), data = ladder)
fitWeights<- predict(polyModel,ladder,interval='confidence',level=0.99);
plot(list.data.covarrubias[[tempName]]$pos,list.data.covarrubias[[tempName]]$wei) +
points(list.data.covarrubias[[tempName]]$pos,fitWeights[,1], typ='l') +
points(list.data.covarrubias[[tempName]]$pos,fitWeights[,1], pch=20)
# ------------------------------------------------------------------------------------------------------------------------------------------------
# check remapped data
full_ladder = data.frame("p"=1:length(tempData[[tempName]][,1]))
fitWeights <- predict(polyModel,full_ladder)
# plot the data
# plot(fitWeights, tempData[[tempName]][,1], typ='l', xlim=c(0, 600), main=tempName)
# zoom into ROI
# p_lo = 350; p_hi =  600; #syt5a | tbx2a
# p_lo = 450; p_hi =  650; # myt1a (wt and not F0)
# p_lo = 400; p_hi =  550; # tbx2a FiRii/FiRiii
# p_lo = 250; p_hi = 420; #sema7a | tbx2b | syt5b | xbp1
# p_lo = 300; p_hi = 500; # foxq2 | nr2f1b | lhx1a
# p_lo = 250; p_hi = 450; #  skor1a | tefa
# p_lo = 200; p_hi = 350; #  lrrfip1a
# p_lo = 100; p_hi = 400; #  xbp1 | tgif | nr2e3
# p_lo = 200; p_hi = 275; #eml1
# p_lo = 100; p_hi = 300; #ntng2b | sall1a
p_lo = 100; p_hi =  650; # whole range | myt1a | skor2 (big deletions)
# p_lo = 460; p_hi =  499; # temp
# plot(fitWeights, tempData[[tempName]][,1], typ='l', xlim=c(p_lo, p_hi), ylim=c(0,20000), main=tempName)
tempPeak = max(tempData[[tempName]][fitWeights>p_lo&fitWeights<p_hi,1]); tempBP =  fitWeights[which(tempData[[tempName]]==tempPeak)];
p_lo2 = 400; p_hi2 =  624;
tempPeak2 = max(tempData[[tempName]][fitWeights>p_lo2&fitWeights<p_hi2,1]); tempBP2 =  fitWeights[which(tempData[[tempName]]==tempPeak2)];
p = ggplot() + geom_line(aes(x = fitWeights, y = tempData[[tempName]][,1]), size=.5) + # frag Data
geom_line(aes(x = fitWeights, y = tempData[[tempName]][,2]), color=rgb(.8, 0, 0, .25)) + #ladder Data
geom_line(aes(x = c(tempBP,tempBP), y = c(0,tempPeak)), color=rgb(0, .5, .8, .8)) + # identified peak
annotate("text", x=tempBP, y=tempPeak*1.05, label=paste(toString(round(tempBP,digits=2)),'bp',sep=' '), size=5) +
annotate("text", x=tempBP+15, y=tempPeak, label=paste(toString(round(tempPeak,digits=0)),'au',sep=' '), size=5, hjust = 0) +
ylab("Fluo (a.u.)") +
xlim(p_lo, p_hi) +
ylim(min(tempData[[tempName]][fitWeights>p_lo&fitWeights<p_hi,1]),1.1*tempPeak) +
ylim(-100,1.1*tempPeak) +
ggtitle(tempName) +
theme_classic(base_size = 16, base_rect_size = 5) +
theme(axis.line = element_line(size = 2), axis.text = element_text(size=14))
# p2 = ggplot() + geom_line(aes(x = fitWeights, y = tempData[[tempName]][,2]), color=rgb(1, 0, 0, .5)) +
#    geom_line(aes(x = c(tempBP,tempBP), y = c(0,max(tempData[[tempName]][,2]))), color=rgb(0, .5, .8, .8)) +
#    ylab("Fluo (a.u.)") +
#    xlim(p_lo, p_hi) +
#    theme_classic()
#
# ggarrange(p, p2, heights = c(2, 0.7),ncol = 1, nrow = 2, align = "v")
ggplotly(p)
# or plot whole ladder by itself
# plot(fitWeights, tempData[[tempName]][,2], typ='l', xlim=c(0, 100))
# export data as csv into same folder and with same name
write.csv(data.frame("size"=fitWeights,"fluo"=tempData[[tempName]][,1],"ladder"=tempData[[tempName]][,2]),paste(paste(dir.fsa,gsub('.{0,4}$', '', tempName),sep = "/"),".csv", sep=""),row.names = FALSE) +
message(paste("Saved analysis for:",tempName)) +
print(tempBP) + print(tempBP2) + print(tempBP2 - tempBP)
# dev.off()
# ------------------------------------------------------------------------------------------------------------------------------------------------
# get single file (run section with command+alt+T)
i=i+1
if (i>length(fsaNames)) {stop('Finished analyzing files')}
tempName = fsaNames[i]; message(paste("Analyzing:",fsaNames[i]))
tempData <- fsaData[tempName]
class(tempData) <- "fsa_stored"
# check if this has been done
if (file.exists(paste(paste(dir.fsa,gsub('.{0,4}$', '', tempName),sep = "/"),".csv", sep=""))) {message("Already calibrated and exported; no need to redo")}
# for fragment analysis using FAM13 and LIZ500, relevant channels are 1 and 5 respectively
chDNA = 1; chLadder = 10;
# plot data to assess if it's worth it remapping
# plot(tempData[[tempName]][,1], typ='l',xlim=c(1700,length(tempData[[tempName]][,1])),ylim=c(0,30000))
dlo=200;
dhi=6100;
plot(tempData[[tempName]][,chDNA], typ='l',xlim=c(dlo,dhi),ylim=c(min(tempData[[tempName]][dlo:dhi,chDNA]),max(tempData[[tempName]][dlo:dhi,chDNA])), main = tempName)
# figure out threshold by checking liz500 channel
plot(tempData[[tempName]][,chLadder], xlim=c(100,2200), typ='l')
ilim01 = 1200;
plot(tempData[[tempName]][,chLadder], xlim =c(ilim01,6000), typ='l')
ilim02 = 6200;
plot(tempData[[tempName]][ilim01:ilim02,chLadder], typ='l') # 16 peaks for liz500 (15 peaks if removed '35' marker)
tempData[[tempName]] = tempData[[tempName]][ilim01:ilim02,c(chDNA,chLadder)]
# plot(tempData[[tempName]][,2], typ='l') # 16 peaks for liz500 (15 peaks if removed '35' marker)
# guessThreshold = quantile(tempData[[tempName]][,2],.992);
guessThreshold = quantile(tempData[[tempName]][,2],.98);
guessThreshold = 50 ;
# match ladder (works better if higher values when noise is high)
ladderData = ladder.info.attach(stored=tempData, ladder=liz500, method='iter2', draw=TRUE, ladd.init.thresh=guessThreshold)
# replot ladder if needed to play with threshold
# plot(tempData[[tempName]][,2], typ='l') # 16 peaks for liz500
# run manual correction if needed
# ladderData = ladder.corrector(stored=tempData, to.correct = tempName, ladder=liz500)
if (file.exists(paste(paste(dir.fsa,gsub('.{0,4}$', '', tempName),sep = "/"),".csv", sep=""))) {message("Already calibrated and exported; no need to redo")}
# ------------------------------------------------------------------------------------------------------------------------------------------------
# ladder is stored as an environment (hidden) variable -> list.data.covarrubias[[tempName]]
ladder = data.frame("p" = list.data.covarrubias[[tempName]]$pos, "w"=list.data.covarrubias[[tempName]]$wei)
# if all fails, do completely manual mapping
# plot(tempData[[tempName]][,2], typ='l', xlim = c(500,1000))
# ladder = data.frame("p" = c(118,270,410,628,685,738,958,1215,1508,1718,1776,2058,2318,2532,2578), "w"=liz500)
# ladder
# fit ladder with a 5th degree polynomial (this is what fragman uses)
polyModel = lm(w ~ poly(p,5), data = ladder)
fitWeights<- predict(polyModel,ladder,interval='confidence',level=0.99);
plot(list.data.covarrubias[[tempName]]$pos,list.data.covarrubias[[tempName]]$wei) +
points(list.data.covarrubias[[tempName]]$pos,fitWeights[,1], typ='l') +
points(list.data.covarrubias[[tempName]]$pos,fitWeights[,1], pch=20)
# ------------------------------------------------------------------------------------------------------------------------------------------------
# check remapped data
full_ladder = data.frame("p"=1:length(tempData[[tempName]][,1]))
fitWeights <- predict(polyModel,full_ladder)
# plot the data
# plot(fitWeights, tempData[[tempName]][,1], typ='l', xlim=c(0, 600), main=tempName)
# zoom into ROI
# p_lo = 350; p_hi =  600; #syt5a | tbx2a
# p_lo = 450; p_hi =  650; # myt1a (wt and not F0)
# p_lo = 400; p_hi =  550; # tbx2a FiRii/FiRiii
# p_lo = 250; p_hi = 420; #sema7a | tbx2b | syt5b | xbp1
# p_lo = 300; p_hi = 500; # foxq2 | nr2f1b | lhx1a
# p_lo = 250; p_hi = 450; #  skor1a | tefa
# p_lo = 200; p_hi = 350; #  lrrfip1a
# p_lo = 100; p_hi = 400; #  xbp1 | tgif | nr2e3
# p_lo = 200; p_hi = 275; #eml1
# p_lo = 100; p_hi = 300; #ntng2b | sall1a
p_lo = 100; p_hi =  650; # whole range | myt1a | skor2 (big deletions)
# p_lo = 460; p_hi =  499; # temp
# plot(fitWeights, tempData[[tempName]][,1], typ='l', xlim=c(p_lo, p_hi), ylim=c(0,20000), main=tempName)
tempPeak = max(tempData[[tempName]][fitWeights>p_lo&fitWeights<p_hi,1]); tempBP =  fitWeights[which(tempData[[tempName]]==tempPeak)];
p_lo2 = 400; p_hi2 =  624;
tempPeak2 = max(tempData[[tempName]][fitWeights>p_lo2&fitWeights<p_hi2,1]); tempBP2 =  fitWeights[which(tempData[[tempName]]==tempPeak2)];
p = ggplot() + geom_line(aes(x = fitWeights, y = tempData[[tempName]][,1]), size=.5) + # frag Data
geom_line(aes(x = fitWeights, y = tempData[[tempName]][,2]), color=rgb(.8, 0, 0, .25)) + #ladder Data
geom_line(aes(x = c(tempBP,tempBP), y = c(0,tempPeak)), color=rgb(0, .5, .8, .8)) + # identified peak
annotate("text", x=tempBP, y=tempPeak*1.05, label=paste(toString(round(tempBP,digits=2)),'bp',sep=' '), size=5) +
annotate("text", x=tempBP+15, y=tempPeak, label=paste(toString(round(tempPeak,digits=0)),'au',sep=' '), size=5, hjust = 0) +
ylab("Fluo (a.u.)") +
xlim(p_lo, p_hi) +
ylim(min(tempData[[tempName]][fitWeights>p_lo&fitWeights<p_hi,1]),1.1*tempPeak) +
ylim(-100,1.1*tempPeak) +
ggtitle(tempName) +
theme_classic(base_size = 16, base_rect_size = 5) +
theme(axis.line = element_line(size = 2), axis.text = element_text(size=14))
# p2 = ggplot() + geom_line(aes(x = fitWeights, y = tempData[[tempName]][,2]), color=rgb(1, 0, 0, .5)) +
#    geom_line(aes(x = c(tempBP,tempBP), y = c(0,max(tempData[[tempName]][,2]))), color=rgb(0, .5, .8, .8)) +
#    ylab("Fluo (a.u.)") +
#    xlim(p_lo, p_hi) +
#    theme_classic()
#
# ggarrange(p, p2, heights = c(2, 0.7),ncol = 1, nrow = 2, align = "v")
ggplotly(p)
# or plot whole ladder by itself
# plot(fitWeights, tempData[[tempName]][,2], typ='l', xlim=c(0, 100))
# export data as csv into same folder and with same name
write.csv(data.frame("size"=fitWeights,"fluo"=tempData[[tempName]][,1],"ladder"=tempData[[tempName]][,2]),paste(paste(dir.fsa,gsub('.{0,4}$', '', tempName),sep = "/"),".csv", sep=""),row.names = FALSE) +
message(paste("Saved analysis for:",tempName)) +
print(tempBP) + print(tempBP2) + print(tempBP2 - tempBP)
# dev.off()
# ------------------------------------------------------------------------------------------------------------------------------------------------
# get single file (run section with command+alt+T)
i=i+1
if (i>length(fsaNames)) {stop('Finished analyzing files')}
tempName = fsaNames[i]; message(paste("Analyzing:",fsaNames[i]))
tempData <- fsaData[tempName]
class(tempData) <- "fsa_stored"
# check if this has been done
if (file.exists(paste(paste(dir.fsa,gsub('.{0,4}$', '', tempName),sep = "/"),".csv", sep=""))) {message("Already calibrated and exported; no need to redo")}
# for fragment analysis using FAM13 and LIZ500, relevant channels are 1 and 5 respectively
chDNA = 1; chLadder = 10;
# plot data to assess if it's worth it remapping
# plot(tempData[[tempName]][,1], typ='l',xlim=c(1700,length(tempData[[tempName]][,1])),ylim=c(0,30000))
dlo=200;
dhi=6100;
plot(tempData[[tempName]][,chDNA], typ='l',xlim=c(dlo,dhi),ylim=c(min(tempData[[tempName]][dlo:dhi,chDNA]),max(tempData[[tempName]][dlo:dhi,chDNA])), main = tempName)
# figure out threshold by checking liz500 channel
plot(tempData[[tempName]][,chLadder], xlim=c(100,2200), typ='l')
ilim01 = 1200;
plot(tempData[[tempName]][,chLadder], xlim =c(ilim01,6000), typ='l')
ilim02 = 6200;
plot(tempData[[tempName]][ilim01:ilim02,chLadder], typ='l') # 16 peaks for liz500 (15 peaks if removed '35' marker)
tempData[[tempName]] = tempData[[tempName]][ilim01:ilim02,c(chDNA,chLadder)]
# plot(tempData[[tempName]][,2], typ='l') # 16 peaks for liz500 (15 peaks if removed '35' marker)
# guessThreshold = quantile(tempData[[tempName]][,2],.992);
guessThreshold = quantile(tempData[[tempName]][,2],.98);
guessThreshold = 50 ;
# match ladder (works better if higher values when noise is high)
ladderData = ladder.info.attach(stored=tempData, ladder=liz500, method='iter2', draw=TRUE, ladd.init.thresh=guessThreshold)
# replot ladder if needed to play with threshold
# plot(tempData[[tempName]][,2], typ='l') # 16 peaks for liz500
# run manual correction if needed
# ladderData = ladder.corrector(stored=tempData, to.correct = tempName, ladder=liz500)
if (file.exists(paste(paste(dir.fsa,gsub('.{0,4}$', '', tempName),sep = "/"),".csv", sep=""))) {message("Already calibrated and exported; no need to redo")}
# ------------------------------------------------------------------------------------------------------------------------------------------------
# ladder is stored as an environment (hidden) variable -> list.data.covarrubias[[tempName]]
ladder = data.frame("p" = list.data.covarrubias[[tempName]]$pos, "w"=list.data.covarrubias[[tempName]]$wei)
# if all fails, do completely manual mapping
# plot(tempData[[tempName]][,2], typ='l', xlim = c(500,1000))
# ladder = data.frame("p" = c(118,270,410,628,685,738,958,1215,1508,1718,1776,2058,2318,2532,2578), "w"=liz500)
# ladder
# fit ladder with a 5th degree polynomial (this is what fragman uses)
polyModel = lm(w ~ poly(p,5), data = ladder)
fitWeights<- predict(polyModel,ladder,interval='confidence',level=0.99);
plot(list.data.covarrubias[[tempName]]$pos,list.data.covarrubias[[tempName]]$wei) +
points(list.data.covarrubias[[tempName]]$pos,fitWeights[,1], typ='l') +
points(list.data.covarrubias[[tempName]]$pos,fitWeights[,1], pch=20)
# ------------------------------------------------------------------------------------------------------------------------------------------------
# check remapped data
full_ladder = data.frame("p"=1:length(tempData[[tempName]][,1]))
fitWeights <- predict(polyModel,full_ladder)
# plot the data
# plot(fitWeights, tempData[[tempName]][,1], typ='l', xlim=c(0, 600), main=tempName)
# zoom into ROI
# p_lo = 350; p_hi =  600; #syt5a | tbx2a
# p_lo = 450; p_hi =  650; # myt1a (wt and not F0)
# p_lo = 400; p_hi =  550; # tbx2a FiRii/FiRiii
# p_lo = 250; p_hi = 420; #sema7a | tbx2b | syt5b | xbp1
# p_lo = 300; p_hi = 500; # foxq2 | nr2f1b | lhx1a
# p_lo = 250; p_hi = 450; #  skor1a | tefa
# p_lo = 200; p_hi = 350; #  lrrfip1a
# p_lo = 100; p_hi = 400; #  xbp1 | tgif | nr2e3
# p_lo = 200; p_hi = 275; #eml1
# p_lo = 100; p_hi = 300; #ntng2b | sall1a
p_lo = 100; p_hi =  650; # whole range | myt1a | skor2 (big deletions)
# p_lo = 460; p_hi =  499; # temp
# plot(fitWeights, tempData[[tempName]][,1], typ='l', xlim=c(p_lo, p_hi), ylim=c(0,20000), main=tempName)
tempPeak = max(tempData[[tempName]][fitWeights>p_lo&fitWeights<p_hi,1]); tempBP =  fitWeights[which(tempData[[tempName]]==tempPeak)];
p_lo2 = 400; p_hi2 =  624;
tempPeak2 = max(tempData[[tempName]][fitWeights>p_lo2&fitWeights<p_hi2,1]); tempBP2 =  fitWeights[which(tempData[[tempName]]==tempPeak2)];
p = ggplot() + geom_line(aes(x = fitWeights, y = tempData[[tempName]][,1]), size=.5) + # frag Data
geom_line(aes(x = fitWeights, y = tempData[[tempName]][,2]), color=rgb(.8, 0, 0, .25)) + #ladder Data
geom_line(aes(x = c(tempBP,tempBP), y = c(0,tempPeak)), color=rgb(0, .5, .8, .8)) + # identified peak
annotate("text", x=tempBP, y=tempPeak*1.05, label=paste(toString(round(tempBP,digits=2)),'bp',sep=' '), size=5) +
annotate("text", x=tempBP+15, y=tempPeak, label=paste(toString(round(tempPeak,digits=0)),'au',sep=' '), size=5, hjust = 0) +
ylab("Fluo (a.u.)") +
xlim(p_lo, p_hi) +
ylim(min(tempData[[tempName]][fitWeights>p_lo&fitWeights<p_hi,1]),1.1*tempPeak) +
ylim(-100,1.1*tempPeak) +
ggtitle(tempName) +
theme_classic(base_size = 16, base_rect_size = 5) +
theme(axis.line = element_line(size = 2), axis.text = element_text(size=14))
# p2 = ggplot() + geom_line(aes(x = fitWeights, y = tempData[[tempName]][,2]), color=rgb(1, 0, 0, .5)) +
#    geom_line(aes(x = c(tempBP,tempBP), y = c(0,max(tempData[[tempName]][,2]))), color=rgb(0, .5, .8, .8)) +
#    ylab("Fluo (a.u.)") +
#    xlim(p_lo, p_hi) +
#    theme_classic()
#
# ggarrange(p, p2, heights = c(2, 0.7),ncol = 1, nrow = 2, align = "v")
ggplotly(p)
# or plot whole ladder by itself
# plot(fitWeights, tempData[[tempName]][,2], typ='l', xlim=c(0, 100))
# export data as csv into same folder and with same name
write.csv(data.frame("size"=fitWeights,"fluo"=tempData[[tempName]][,1],"ladder"=tempData[[tempName]][,2]),paste(paste(dir.fsa,gsub('.{0,4}$', '', tempName),sep = "/"),".csv", sep=""),row.names = FALSE) +
message(paste("Saved analysis for:",tempName)) +
print(tempBP) + print(tempBP2) + print(tempBP2 - tempBP)
# dev.off()
# ------------------------------------------------------------------------------------------------------------------------------------------------
# get single file (run section with command+alt+T)
i=i+1
if (i>length(fsaNames)) {stop('Finished analyzing files')}
tempName = fsaNames[i]; message(paste("Analyzing:",fsaNames[i]))
tempData <- fsaData[tempName]
class(tempData) <- "fsa_stored"
# check if this has been done
if (file.exists(paste(paste(dir.fsa,gsub('.{0,4}$', '', tempName),sep = "/"),".csv", sep=""))) {message("Already calibrated and exported; no need to redo")}
# for fragment analysis using FAM13 and LIZ500, relevant channels are 1 and 5 respectively
chDNA = 1; chLadder = 10;
# plot data to assess if it's worth it remapping
# plot(tempData[[tempName]][,1], typ='l',xlim=c(1700,length(tempData[[tempName]][,1])),ylim=c(0,30000))
dlo=200;
dhi=6100;
plot(tempData[[tempName]][,chDNA], typ='l',xlim=c(dlo,dhi),ylim=c(min(tempData[[tempName]][dlo:dhi,chDNA]),max(tempData[[tempName]][dlo:dhi,chDNA])), main = tempName)
# figure out threshold by checking liz500 channel
plot(tempData[[tempName]][,chLadder], xlim=c(100,2200), typ='l')
ilim01 = 1200;
plot(tempData[[tempName]][,chLadder], xlim =c(ilim01,6000), typ='l')
ilim02 = 6200;
plot(tempData[[tempName]][ilim01:ilim02,chLadder], typ='l') # 16 peaks for liz500 (15 peaks if removed '35' marker)
tempData[[tempName]] = tempData[[tempName]][ilim01:ilim02,c(chDNA,chLadder)]
# plot(tempData[[tempName]][,2], typ='l') # 16 peaks for liz500 (15 peaks if removed '35' marker)
# guessThreshold = quantile(tempData[[tempName]][,2],.992);
guessThreshold = quantile(tempData[[tempName]][,2],.98);
guessThreshold = 50 ;
# match ladder (works better if higher values when noise is high)
ladderData = ladder.info.attach(stored=tempData, ladder=liz500, method='iter2', draw=TRUE, ladd.init.thresh=guessThreshold)
# replot ladder if needed to play with threshold
# plot(tempData[[tempName]][,2], typ='l') # 16 peaks for liz500
# run manual correction if needed
# ladderData = ladder.corrector(stored=tempData, to.correct = tempName, ladder=liz500)
if (file.exists(paste(paste(dir.fsa,gsub('.{0,4}$', '', tempName),sep = "/"),".csv", sep=""))) {message("Already calibrated and exported; no need to redo")}
# ------------------------------------------------------------------------------------------------------------------------------------------------
# ladder is stored as an environment (hidden) variable -> list.data.covarrubias[[tempName]]
ladder = data.frame("p" = list.data.covarrubias[[tempName]]$pos, "w"=list.data.covarrubias[[tempName]]$wei)
# if all fails, do completely manual mapping
# plot(tempData[[tempName]][,2], typ='l', xlim = c(500,1000))
# ladder = data.frame("p" = c(118,270,410,628,685,738,958,1215,1508,1718,1776,2058,2318,2532,2578), "w"=liz500)
# ladder
# fit ladder with a 5th degree polynomial (this is what fragman uses)
polyModel = lm(w ~ poly(p,5), data = ladder)
fitWeights<- predict(polyModel,ladder,interval='confidence',level=0.99);
plot(list.data.covarrubias[[tempName]]$pos,list.data.covarrubias[[tempName]]$wei) +
points(list.data.covarrubias[[tempName]]$pos,fitWeights[,1], typ='l') +
points(list.data.covarrubias[[tempName]]$pos,fitWeights[,1], pch=20)
# ------------------------------------------------------------------------------------------------------------------------------------------------
# check remapped data
full_ladder = data.frame("p"=1:length(tempData[[tempName]][,1]))
fitWeights <- predict(polyModel,full_ladder)
# plot the data
# plot(fitWeights, tempData[[tempName]][,1], typ='l', xlim=c(0, 600), main=tempName)
# zoom into ROI
# p_lo = 350; p_hi =  600; #syt5a | tbx2a
# p_lo = 450; p_hi =  650; # myt1a (wt and not F0)
# p_lo = 400; p_hi =  550; # tbx2a FiRii/FiRiii
# p_lo = 250; p_hi = 420; #sema7a | tbx2b | syt5b | xbp1
# p_lo = 300; p_hi = 500; # foxq2 | nr2f1b | lhx1a
# p_lo = 250; p_hi = 450; #  skor1a | tefa
# p_lo = 200; p_hi = 350; #  lrrfip1a
# p_lo = 100; p_hi = 400; #  xbp1 | tgif | nr2e3
# p_lo = 200; p_hi = 275; #eml1
# p_lo = 100; p_hi = 300; #ntng2b | sall1a
p_lo = 100; p_hi =  650; # whole range | myt1a | skor2 (big deletions)
# p_lo = 460; p_hi =  499; # temp
# plot(fitWeights, tempData[[tempName]][,1], typ='l', xlim=c(p_lo, p_hi), ylim=c(0,20000), main=tempName)
tempPeak = max(tempData[[tempName]][fitWeights>p_lo&fitWeights<p_hi,1]); tempBP =  fitWeights[which(tempData[[tempName]]==tempPeak)];
p_lo2 = 400; p_hi2 =  624;
tempPeak2 = max(tempData[[tempName]][fitWeights>p_lo2&fitWeights<p_hi2,1]); tempBP2 =  fitWeights[which(tempData[[tempName]]==tempPeak2)];
p = ggplot() + geom_line(aes(x = fitWeights, y = tempData[[tempName]][,1]), size=.5) + # frag Data
geom_line(aes(x = fitWeights, y = tempData[[tempName]][,2]), color=rgb(.8, 0, 0, .25)) + #ladder Data
geom_line(aes(x = c(tempBP,tempBP), y = c(0,tempPeak)), color=rgb(0, .5, .8, .8)) + # identified peak
annotate("text", x=tempBP, y=tempPeak*1.05, label=paste(toString(round(tempBP,digits=2)),'bp',sep=' '), size=5) +
annotate("text", x=tempBP+15, y=tempPeak, label=paste(toString(round(tempPeak,digits=0)),'au',sep=' '), size=5, hjust = 0) +
ylab("Fluo (a.u.)") +
xlim(p_lo, p_hi) +
ylim(min(tempData[[tempName]][fitWeights>p_lo&fitWeights<p_hi,1]),1.1*tempPeak) +
ylim(-100,1.1*tempPeak) +
ggtitle(tempName) +
theme_classic(base_size = 16, base_rect_size = 5) +
theme(axis.line = element_line(size = 2), axis.text = element_text(size=14))
# p2 = ggplot() + geom_line(aes(x = fitWeights, y = tempData[[tempName]][,2]), color=rgb(1, 0, 0, .5)) +
#    geom_line(aes(x = c(tempBP,tempBP), y = c(0,max(tempData[[tempName]][,2]))), color=rgb(0, .5, .8, .8)) +
#    ylab("Fluo (a.u.)") +
#    xlim(p_lo, p_hi) +
#    theme_classic()
#
# ggarrange(p, p2, heights = c(2, 0.7),ncol = 1, nrow = 2, align = "v")
ggplotly(p)
# or plot whole ladder by itself
# plot(fitWeights, tempData[[tempName]][,2], typ='l', xlim=c(0, 100))
# export data as csv into same folder and with same name
write.csv(data.frame("size"=fitWeights,"fluo"=tempData[[tempName]][,1],"ladder"=tempData[[tempName]][,2]),paste(paste(dir.fsa,gsub('.{0,4}$', '', tempName),sep = "/"),".csv", sep=""),row.names = FALSE) +
message(paste("Saved analysis for:",tempName)) +
print(tempBP) + print(tempBP2) + print(tempBP2 - tempBP)
# dev.off()
# ------------------------------------------------------------------------------------------------------------------------------------------------
# get single file (run section with command+alt+T)
i=i+1
if (i>length(fsaNames)) {stop('Finished analyzing files')}
tempName = fsaNames[i]; message(paste("Analyzing:",fsaNames[i]))
tempData <- fsaData[tempName]
class(tempData) <- "fsa_stored"
# check if this has been done
if (file.exists(paste(paste(dir.fsa,gsub('.{0,4}$', '', tempName),sep = "/"),".csv", sep=""))) {message("Already calibrated and exported; no need to redo")}
# for fragment analysis using FAM13 and LIZ500, relevant channels are 1 and 5 respectively
chDNA = 1; chLadder = 10;
# plot data to assess if it's worth it remapping
# plot(tempData[[tempName]][,1], typ='l',xlim=c(1700,length(tempData[[tempName]][,1])),ylim=c(0,30000))
dlo=200;
dhi=6100;
plot(tempData[[tempName]][,chDNA], typ='l',xlim=c(dlo,dhi),ylim=c(min(tempData[[tempName]][dlo:dhi,chDNA]),max(tempData[[tempName]][dlo:dhi,chDNA])), main = tempName)
# figure out threshold by checking liz500 channel
plot(tempData[[tempName]][,chLadder], xlim=c(100,2200), typ='l')
ilim01 = 1200;
plot(tempData[[tempName]][,chLadder], xlim =c(ilim01,6000), typ='l')
ilim02 = 6200;
plot(tempData[[tempName]][ilim01:ilim02,chLadder], typ='l') # 16 peaks for liz500 (15 peaks if removed '35' marker)
tempData[[tempName]] = tempData[[tempName]][ilim01:ilim02,c(chDNA,chLadder)]
# plot(tempData[[tempName]][,2], typ='l') # 16 peaks for liz500 (15 peaks if removed '35' marker)
# guessThreshold = quantile(tempData[[tempName]][,2],.992);
guessThreshold = quantile(tempData[[tempName]][,2],.98);
guessThreshold = 50 ;
# match ladder (works better if higher values when noise is high)
ladderData = ladder.info.attach(stored=tempData, ladder=liz500, method='iter2', draw=TRUE, ladd.init.thresh=guessThreshold)
# replot ladder if needed to play with threshold
# plot(tempData[[tempName]][,2], typ='l') # 16 peaks for liz500
# run manual correction if needed
# ladderData = ladder.corrector(stored=tempData, to.correct = tempName, ladder=liz500)
if (file.exists(paste(paste(dir.fsa,gsub('.{0,4}$', '', tempName),sep = "/"),".csv", sep=""))) {message("Already calibrated and exported; no need to redo")}
# ------------------------------------------------------------------------------------------------------------------------------------------------
# ladder is stored as an environment (hidden) variable -> list.data.covarrubias[[tempName]]
ladder = data.frame("p" = list.data.covarrubias[[tempName]]$pos, "w"=list.data.covarrubias[[tempName]]$wei)
# if all fails, do completely manual mapping
# plot(tempData[[tempName]][,2], typ='l', xlim = c(500,1000))
# ladder = data.frame("p" = c(118,270,410,628,685,738,958,1215,1508,1718,1776,2058,2318,2532,2578), "w"=liz500)
# ladder
# fit ladder with a 5th degree polynomial (this is what fragman uses)
polyModel = lm(w ~ poly(p,5), data = ladder)
fitWeights<- predict(polyModel,ladder,interval='confidence',level=0.99);
plot(list.data.covarrubias[[tempName]]$pos,list.data.covarrubias[[tempName]]$wei) +
points(list.data.covarrubias[[tempName]]$pos,fitWeights[,1], typ='l') +
points(list.data.covarrubias[[tempName]]$pos,fitWeights[,1], pch=20)
# ------------------------------------------------------------------------------------------------------------------------------------------------
# check remapped data
full_ladder = data.frame("p"=1:length(tempData[[tempName]][,1]))
fitWeights <- predict(polyModel,full_ladder)
# plot the data
# plot(fitWeights, tempData[[tempName]][,1], typ='l', xlim=c(0, 600), main=tempName)
# zoom into ROI
# p_lo = 350; p_hi =  600; #syt5a | tbx2a
# p_lo = 450; p_hi =  650; # myt1a (wt and not F0)
# p_lo = 400; p_hi =  550; # tbx2a FiRii/FiRiii
# p_lo = 250; p_hi = 420; #sema7a | tbx2b | syt5b | xbp1
# p_lo = 300; p_hi = 500; # foxq2 | nr2f1b | lhx1a
# p_lo = 250; p_hi = 450; #  skor1a | tefa
# p_lo = 200; p_hi = 350; #  lrrfip1a
# p_lo = 100; p_hi = 400; #  xbp1 | tgif | nr2e3
# p_lo = 200; p_hi = 275; #eml1
# p_lo = 100; p_hi = 300; #ntng2b | sall1a
p_lo = 100; p_hi =  650; # whole range | myt1a | skor2 (big deletions)
# p_lo = 460; p_hi =  499; # temp
# plot(fitWeights, tempData[[tempName]][,1], typ='l', xlim=c(p_lo, p_hi), ylim=c(0,20000), main=tempName)
tempPeak = max(tempData[[tempName]][fitWeights>p_lo&fitWeights<p_hi,1]); tempBP =  fitWeights[which(tempData[[tempName]]==tempPeak)];
p_lo2 = 400; p_hi2 =  624;
tempPeak2 = max(tempData[[tempName]][fitWeights>p_lo2&fitWeights<p_hi2,1]); tempBP2 =  fitWeights[which(tempData[[tempName]]==tempPeak2)];
p = ggplot() + geom_line(aes(x = fitWeights, y = tempData[[tempName]][,1]), size=.5) + # frag Data
geom_line(aes(x = fitWeights, y = tempData[[tempName]][,2]), color=rgb(.8, 0, 0, .25)) + #ladder Data
geom_line(aes(x = c(tempBP,tempBP), y = c(0,tempPeak)), color=rgb(0, .5, .8, .8)) + # identified peak
annotate("text", x=tempBP, y=tempPeak*1.05, label=paste(toString(round(tempBP,digits=2)),'bp',sep=' '), size=5) +
annotate("text", x=tempBP+15, y=tempPeak, label=paste(toString(round(tempPeak,digits=0)),'au',sep=' '), size=5, hjust = 0) +
ylab("Fluo (a.u.)") +
xlim(p_lo, p_hi) +
ylim(min(tempData[[tempName]][fitWeights>p_lo&fitWeights<p_hi,1]),1.1*tempPeak) +
ylim(-100,1.1*tempPeak) +
ggtitle(tempName) +
theme_classic(base_size = 16, base_rect_size = 5) +
theme(axis.line = element_line(size = 2), axis.text = element_text(size=14))
# p2 = ggplot() + geom_line(aes(x = fitWeights, y = tempData[[tempName]][,2]), color=rgb(1, 0, 0, .5)) +
#    geom_line(aes(x = c(tempBP,tempBP), y = c(0,max(tempData[[tempName]][,2]))), color=rgb(0, .5, .8, .8)) +
#    ylab("Fluo (a.u.)") +
#    xlim(p_lo, p_hi) +
#    theme_classic()
#
# ggarrange(p, p2, heights = c(2, 0.7),ncol = 1, nrow = 2, align = "v")
ggplotly(p)
# or plot whole ladder by itself
# plot(fitWeights, tempData[[tempName]][,2], typ='l', xlim=c(0, 100))
# export data as csv into same folder and with same name
write.csv(data.frame("size"=fitWeights,"fluo"=tempData[[tempName]][,1],"ladder"=tempData[[tempName]][,2]),paste(paste(dir.fsa,gsub('.{0,4}$', '', tempName),sep = "/"),".csv", sep=""),row.names = FALSE) +
message(paste("Saved analysis for:",tempName)) +
print(tempBP) + print(tempBP2) + print(tempBP2 - tempBP)
# dev.off()
# ------------------------------------------------------------------------------------------------------------------------------------------------
# get single file (run section with command+alt+T)
i=i+1
if (i>length(fsaNames)) {stop('Finished analyzing files')}
# ------------------------------------------------------------------------------------------------------------------------------------------------
# ------------------------------------------------------------------------------------------------------------------------------------------------
# Clear environment
rm(list=ls());
try(dev.off(),silent=TRUE);
