{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import h5py\n",
    "\n",
    "class espion_file:\n",
    "    \"\"\"Loader for erg ESPION CSV files into Python\"\"\"\n",
    "    def __init__(self, filepath, filename, species, genotype):\n",
    "        self.basedir = \"/Users/angueyraaristjm/Documents/LiData/invivoERG/\"\n",
    "        self.filepath = filepath\n",
    "        self.filename = filename\n",
    "        self.savepath = self.basedir + self.filepath + \"/\"\n",
    "        self.fullpath = self.savepath + self.filename + \".csv\"\n",
    "        self.species = species\n",
    "        self.genotype = genotype\n",
    "        self.metadata = self.pull_metadata()\n",
    "        self.datatable = self.pull_datatable()\n",
    "        self.data = self.pull_data()\n",
    "        self.HDF5remap()\n",
    "    \n",
    "    def pull_metadata(self):\n",
    "        # pull and parse metadata information\n",
    "        csvparams = pandas.read_csv(self.fullpath, header=1, usecols=[0, 1], nrows=10, low_memory=False)\n",
    "        csvparams = csvparams.dropna()\n",
    "        metadata = dict()\n",
    "        intfields = [\"Steps\", \"Channels\"]\n",
    "        datefields = [\"DOB\", \"Date performed\"]\n",
    "        for i in range(1, 10):\n",
    "            if csvparams.Parameter[i] in intfields:\n",
    "                metadata[csvparams.Parameter[i]] = int(csvparams.Value[i])\n",
    "            elif csvparams.Parameter[i] in datefields:\n",
    "                metadata[csvparams.Parameter[i]] = pandas.to_datetime(csvparams.Value[i])\n",
    "            elif csvparams.Parameter[i] == \"Family Name\":\n",
    "                metadata[\"ID\"] = csvparams.Value[i]\n",
    "            else: \n",
    "                metadata[csvparams.Parameter[i]] = csvparams.Value[i]\n",
    "        metadata['Species'] = self.species\n",
    "        metadata['genotype'] = self.genotype\n",
    "        return metadata\n",
    "                \n",
    "    def pull_datatable(self):\n",
    "        # pull datatable to parse data\n",
    "        fullcsv = pandas.read_csv(self.fullpath, header=0, low_memory=False)\n",
    "        if \"Data Table\" in fullcsv:\n",
    "            #print(\"Data Table is Right\")\n",
    "            datatable = pandas.read_csv(self.fullpath, header=1, usecols=[3, 4, 5, 8], low_memory=False)\n",
    "            datatable = datatable.dropna()\n",
    "            datatable = datatable.astype(int)\n",
    "        elif fullcsv.iloc[12, 0] == \"Data Table\":\n",
    "#         elif fullcsv.ix[12, 0] == \"Data Table\":\n",
    "            #print(\"Data Table is Below\")\n",
    "            datatable = pandas.read_csv(self.fullpath, header=1, usecols=[0, 1, 2, 5], skiprows=13, low_memory=False)\n",
    "            datatable = datatable.dropna()\n",
    "            datatable = datatable.astype(int)\n",
    "        elif fullcsv.iloc[13, 0] == \"Data Table\":\n",
    "#         elif fullcsv.ix[13, 0] == \"Data Table\":\n",
    "            #print(\"Data Table is Below\")\n",
    "            datatable = pandas.read_csv(self.fullpath, header=1, usecols=[0, 1, 2, 5], skiprows=14, low_memory=False)\n",
    "            datatable = datatable.dropna()\n",
    "            datatable = datatable.astype(int)\n",
    "        else:\n",
    "            print(\"Did not find datatable\")\n",
    "        return datatable\n",
    "    \n",
    "    def pull_data(self):\n",
    "        # parse data based on data table\n",
    "        fullcsv = pandas.read_csv(self.fullpath, header=0, low_memory=False)\n",
    "        data = dict()\n",
    "        for step in range(self.metadata['Steps']):\n",
    "            stepname = \"Step\" + str(step+1).zfill(2)\n",
    "            # print(stepname)\n",
    "            ch1start = self.datatable.Column[(self.datatable.Step==(int(step+1))) & (self.datatable.Chan==1)]\n",
    "            ch2start = self.datatable.Column[(self.datatable.Step==(int(step+1))) & (self.datatable.Chan==2)]\n",
    "            ntrials = self.datatable.Trials[(self.datatable.Step==(int(step+1))) & (self.datatable.Chan==1)]\n",
    "            if len(ch1start)==1:\n",
    "                #normally each step runs only once but if it's repeated, ESPION doubles the entries\n",
    "                ch1start = int(ch1start)\n",
    "                ch2start = int(ch2start-1)\n",
    "                ntrials = int(ntrials)\n",
    "                data[stepname] = self.espion_step(ch1start=ch1start, ch2start=ch2start, ntrials=ntrials, csvtable=fullcsv)\n",
    "            elif len(ch1start.unique())==1:\n",
    "                #found duplicates but all have the same column start\n",
    "                ch1start = int(ch1start.unique())\n",
    "                ch2start = int(ch2start.unique()-1)\n",
    "                ntrials = int(ntrials.sum())\n",
    "                data[stepname] = self.espion_step(ch1start=ch1start, ch2start=ch2start, ntrials=ntrials, csvtable=fullcsv)\n",
    "        return data\n",
    "    \n",
    "    @staticmethod\n",
    "    def espion_step(ch1start, ch2start, ntrials, csvtable):\n",
    "        \"\"\"Loader for a single erg ESPION step\"\"\"\n",
    "        colstart = ch1start-1\n",
    "        colend = colstart+1+(ntrials*2)\n",
    "        currcsv = csvtable.iloc[0:, colstart:colend].copy(deep=0)\n",
    "        currcsv = currcsv.dropna().reset_index(drop=True)\n",
    "        currcsv = currcsv.drop(0).reset_index(drop=True)\n",
    "        colnames = []\n",
    "        ch1cnt = 0\n",
    "        ch2cnt = 0\n",
    "        for i in range(0, len(currcsv.columns)):\n",
    "            currcsv.iloc[0:, i] = pandas.to_numeric(currcsv.iloc[0:, i])\n",
    "            if i == 0:\n",
    "                colnames.append('t')\n",
    "            elif 1 <= i < 1+ntrials:\n",
    "                ch1cnt += 1\n",
    "                colnames.append('L' + str(ch1cnt).zfill(2))\n",
    "            elif 1+ntrials <= i < 1+(ntrials*2):\n",
    "                ch2cnt += 1\n",
    "                colnames.append('R' + str(ch2cnt).zfill(2))\n",
    "        currcsv.columns = colnames\n",
    "        currcsv = currcsv.divide(1000)\n",
    "        csvoutput = currcsv.copy()\n",
    "        return csvoutput\n",
    "\n",
    "    def HDF5remap(self):\n",
    "        dt = h5py.special_dtype(vlen=bytes)\n",
    "        intfields = [\"Steps\", \"Channels\"]\n",
    "        \n",
    "        h5name = self.savepath + self.filename + \".h5\"\n",
    "        print('Saving h5 file...')\n",
    "        with h5py.File(h5name, 'w') as hfile:\n",
    "#             print('\\tFrom datatable:')\n",
    "            for col in self.datatable.columns:\n",
    "                hfile.create_dataset(col.replace(' ','_'), data=self.datatable.get(col))\n",
    "#                 print('\\t\\t'+ col)\n",
    "#             print('\\tFrom metadata:')\n",
    "            for key in self.metadata:\n",
    "                if key in intfields:\n",
    "                    hfile.attrs.create(key.replace(' ','_'), data=self.metadata[key])\n",
    "                else:\n",
    "                    hfile.attrs.create(key.replace(' ','_'), data=str(self.metadata[key]), dtype=dt)\n",
    "#                 print('\\t\\t' + key)\n",
    "            # print('\\tFrom data:')\n",
    "            for step in self.data:\n",
    "                group = hfile.create_group(step)\n",
    "                group.create_dataset('t', data=self.data[step].filter(regex = 't'))\n",
    "                group.create_dataset('L', data=self.data[step].filter(regex = 'L'))\n",
    "                group.create_dataset('R', data=self.data[step].filter(regex = 'R'))\n",
    "                # print('\\t\\t' + step)\n",
    "        print('Saved to: ' + h5name + '\\n')\n",
    "        \n",
    "# if __name__ == \"__main__\":\n",
    "#     a = espion_file(\"20160928/20160928_wl05_2_eml1het\", \"20160928_wl05_2_01_iSscotdark\", \"Mouse\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving h5 file...\n",
      "Saved to: /Users/angueyraaristjm/Documents/LiData/invivoERG/20170309/20170309_wl05_107_wt/01_iSeriesScotopicStitch.h5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# map a single espion csv exported file to hdf5\n",
    "a = espion_file(\"20170309/20170309_wl05_107_wt\", \"01_iSeriesScotopicStitch\", \"Mouse\", \"wt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# genotypes\n",
    "# wt\n",
    "# eml1+/-\n",
    "# eml1-/-\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving h5 file...\n",
      "Saved to: /Users/angueyraaristjm/Documents/LiData/invivoERG/20171025/20171025_Sq1040_MB001High/01_IseriesPre.h5\n",
      "\n",
      "Saving h5 file...\n",
      "Saved to: /Users/angueyraaristjm/Documents/LiData/invivoERG/20171025/20171025_Sq1040_MB001High/02_FlashPre.h5\n",
      "\n",
      "Saving h5 file...\n",
      "Saved to: /Users/angueyraaristjm/Documents/LiData/invivoERG/20171025/20171025_Sq1040_MB001High/02a_FlashesPreDimmer.h5\n",
      "\n",
      "Saving h5 file...\n",
      "Saved to: /Users/angueyraaristjm/Documents/LiData/invivoERG/20171025/20171025_Sq1040_MB001High/03_FlashPost0s.h5\n",
      "\n",
      "Saving h5 file...\n",
      "Saved to: /Users/angueyraaristjm/Documents/LiData/invivoERG/20171025/20171025_Sq1040_MB001High/04_FlashPost1min19s.h5\n",
      "\n",
      "Saving h5 file...\n",
      "Saved to: /Users/angueyraaristjm/Documents/LiData/invivoERG/20171025/20171025_Sq1040_MB001High/05_FlashPost2min53s.h5\n",
      "\n",
      "Saving h5 file...\n",
      "Saved to: /Users/angueyraaristjm/Documents/LiData/invivoERG/20171025/20171025_Sq1040_MB001High/06_FlashPost4min20s.h5\n",
      "\n",
      "Saving h5 file...\n",
      "Saved to: /Users/angueyraaristjm/Documents/LiData/invivoERG/20171025/20171025_Sq1040_MB001High/07_FlashPost5min48s.h5\n",
      "\n",
      "Saving h5 file...\n",
      "Saved to: /Users/angueyraaristjm/Documents/LiData/invivoERG/20171025/20171025_Sq1040_MB001High/08_FlashPost7min14s.h5\n",
      "\n",
      "Saving h5 file...\n",
      "Saved to: /Users/angueyraaristjm/Documents/LiData/invivoERG/20171025/20171025_Sq1040_MB001High/09_FlashPost8min37s.h5\n",
      "\n",
      "Saving h5 file...\n",
      "Saved to: /Users/angueyraaristjm/Documents/LiData/invivoERG/20171025/20171025_Sq1040_MB001High/10_IseriesPost.h5\n",
      "\n",
      "Saving h5 file...\n",
      "Saved to: /Users/angueyraaristjm/Documents/LiData/invivoERG/20171025/20171025_Sq1040_MB001High/11_FlashPost13min55s.h5\n",
      "\n",
      "Saving h5 file...\n",
      "Saved to: /Users/angueyraaristjm/Documents/LiData/invivoERG/20171025/20171025_Sq1040_MB001High/12_FlashPost15min23s.h5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# map all espion csv exported files on a single folder to hdf5\n",
    "import os\n",
    "\n",
    "path={};\n",
    "path['datafolder']='20171025/20171025_Sq1040_MB001High'\n",
    "path['species']='Squirrel'\n",
    "path['root'] = '/Users/angueyraaristjm/Documents/LiData/invivoERG/'\n",
    "path['fullpath']=path['root']+path['datafolder']+'/'\n",
    "path['genotype']='Wild'\n",
    "\n",
    "for root, dirs, files in os.walk(path['fullpath'], topdown=True):\n",
    "    dirs.clear() #with topdown true, this will prevent walk from going into subs\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            fName=file[:-4]\n",
    "            if (fName + \".h5\") in files:\n",
    "                print(fName + ' is already mapped')\n",
    "            else:\n",
    "                erg = espion_file(path['datafolder'], fName, path['species'],path['genotype'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dirData = '20160819/20160819_Sq813';\n",
      "dirFile = '20160819_Sq813_01_IsXeMax';\n",
      "dirFile = '20160819_Sq813_02_Steps2sG_pre';\n",
      "dirFile = '20160819_Sq813_03_sines';\n",
      "dirFile = '20160819_Sq813_04_Flashes_pre';\n",
      "dirFile = '20160819_Sq813_05_Flashes_posti_0min';\n",
      "dirFile = '20160819_Sq813_06_Flashes_posti_3min';\n",
      "dirFile = '20160819_Sq813_07_Flashes_posti_7min';\n",
      "dirFile = '20160819_Sq813_08_IsXeMax_posti_10min';\n",
      "dirFile = '20160819_Sq813_09_Steps2sG_posti';\n",
      "dirFile = '20160819_Sq813_10_Flashes_preii';\n",
      "dirFile = '20160819_Sq813_11_Flashes_postii_0min';\n",
      "dirFile = '20160819_Sq813_12_Flashes_postii_2o5min';\n",
      "dirFile = '20160819_Sq813_13_Flashes_postii_5min';\n",
      "dirFile = '20160819_Sq813_14_IsXeMax_postii_8min';\n",
      "dirFile = '20160819_Sq813_15_Steps2sG_postii';\n"
     ]
    }
   ],
   "source": [
    "# spit out list of csv files\n",
    "import os\n",
    "\n",
    "path={};\n",
    "path['datafolder']='20160819/20160819_Sq813'\n",
    "path['species']='Squirrel'\n",
    "path['root'] = '/Users/angueyraaristjm/Documents/LiData/invivoERG/'\n",
    "path['fullpath']=path['root']+path['datafolder']+'/'\n",
    "\n",
    "print('dirData = \\'' + path['datafolder'] + '\\';')\n",
    "for root, dirs, files in os.walk(path['fullpath'], topdown=True):\n",
    "    dirs.clear() #with topdown true, this will prevent walk from going into subs\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            fName=file[:-4]\n",
    "            print('dirFile = \\'' + fName + '\\';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function print in module builtins:\n",
      "\n",
      "print(...)\n",
      "    print(value, ..., sep=' ', end='\\n', file=sys.stdout, flush=False)\n",
      "    \n",
      "    Prints the values to a stream, or to sys.stdout by default.\n",
      "    Optional keyword arguments:\n",
      "    file:  a file-like object (stream); defaults to the current sys.stdout.\n",
      "    sep:   string inserted between values, default a space.\n",
      "    end:   string appended after the last value, default a newline.\n",
      "    flush: whether to forcibly flush the stream.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help (print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
